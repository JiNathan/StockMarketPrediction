{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlW2xTdt3YY2",
        "outputId": "95e92738-10d0-4c57-8a1e-bdc60d13daca"
      },
      "outputs": [],
      "source": [
        "#-------Imports-------\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "#-------USE BELOW CODE ON COLLAB, else comment it out-------\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "ehh9BrNx2P8p",
        "outputId": "dab067e5-7fd6-4a65-d572-923cbcc02c69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>published_at</th>\n",
              "      <th>short_description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Santoli’s Wednesday market notes: Could Septem...</td>\n",
              "      <td>2021-09-29T17:09:39+0000</td>\n",
              "      <td>This is the daily notebook of Mike Santoli, CN...</td>\n",
              "      <td>cnbc, Premium, Articles, Investment strategy, ...</td>\n",
              "      <td>This is the daily notebook of Mike Santoli, CN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My take on the early Brexit winners and losers</td>\n",
              "      <td>2016-06-24T13:50:48-0400</td>\n",
              "      <td>This commentary originally ran on Facebook. Bo...</td>\n",
              "      <td>Articles, Politics, Europe News, European Cent...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Europe&amp;#039;s recovery depends on Renzi&amp;#039;s...</td>\n",
              "      <td>2014-03-25T13:29:45-0400</td>\n",
              "      <td>In spring, ambitious reforms began in Italy. U...</td>\n",
              "      <td>Articles, Business News, Economy, Europe Econo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US Moves Closer to Becoming A Major Shareholde...</td>\n",
              "      <td>2009-04-22T19:49:03+0000</td>\n",
              "      <td>The US government is increasingly likely to co...</td>\n",
              "      <td>cnbc, Articles, General Motors Co, Business Ne...</td>\n",
              "      <td>The US government is increasingly likely to co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump: 'Mission accomplished' on 'perfectly ex...</td>\n",
              "      <td>2018-04-14T14:59:04+0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnbc, Articles, George W. Bush, Vladimir Putin...</td>\n",
              "      <td>President Donald Trump hailed the U.S.-led int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>GLOBAL MARKETS-Euro rises on Spain speculation...</td>\n",
              "      <td>2012-10-02T18:23:00+0000</td>\n",
              "      <td>(Adds comment, details, updates prices)* Spain...</td>\n",
              "      <td>cnbc, Articles, Caterpillar Inc, Europe, Washi...</td>\n",
              "      <td>(Adds comment, details, updates prices)* Spain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>'I come to bury Bitcoin, not to praise it': UBS</td>\n",
              "      <td>2018-11-30T11:38:30+0000</td>\n",
              "      <td>Cryptocurrencies are nearing the end of the ro...</td>\n",
              "      <td>cnbc, Articles, Bitcoin/USD Bitfinex, Economy,...</td>\n",
              "      <td>Cryptocurrencies are nearing the end of the ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Jon Stewart joins Stephen Colbert to mock that...</td>\n",
              "      <td>2016-07-22T11:44:12+0000</td>\n",
              "      <td>It's been 351 days since Jon Stewart sat behin...</td>\n",
              "      <td>cnbc, Articles, Donald Trump, Media, Elections...</td>\n",
              "      <td>It's been 351 days since Jon Stewart sat behin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Will Stocks Resist 'Anything but Utmost Catast...</td>\n",
              "      <td>2011-11-17T11:50:06+0000</td>\n",
              "      <td>Stock markets have taken such a beating over t...</td>\n",
              "      <td>cnbc, Articles, Business News, Economy, World ...</td>\n",
              "      <td>Stock markets have taken such a beating over t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Biden plans to visit Texas, ask FEMA to accele...</td>\n",
              "      <td>2021-02-19T16:48:01+0000</td>\n",
              "      <td>President Joe Biden said Friday that he plans ...</td>\n",
              "      <td>cnbc, Articles, Breaking News: Politics, Joe B...</td>\n",
              "      <td>President Joe Biden said Friday that he plans ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0   Santoli’s Wednesday market notes: Could Septem...   \n",
              "1      My take on the early Brexit winners and losers   \n",
              "2   Europe&#039;s recovery depends on Renzi&#039;s...   \n",
              "3   US Moves Closer to Becoming A Major Shareholde...   \n",
              "4   Trump: 'Mission accomplished' on 'perfectly ex...   \n",
              "..                                                ...   \n",
              "95  GLOBAL MARKETS-Euro rises on Spain speculation...   \n",
              "96   'I come to bury Bitcoin, not to praise it': UBS    \n",
              "97  Jon Stewart joins Stephen Colbert to mock that...   \n",
              "98  Will Stocks Resist 'Anything but Utmost Catast...   \n",
              "99  Biden plans to visit Texas, ask FEMA to accele...   \n",
              "\n",
              "                published_at  \\\n",
              "0   2021-09-29T17:09:39+0000   \n",
              "1   2016-06-24T13:50:48-0400   \n",
              "2   2014-03-25T13:29:45-0400   \n",
              "3   2009-04-22T19:49:03+0000   \n",
              "4   2018-04-14T14:59:04+0000   \n",
              "..                       ...   \n",
              "95  2012-10-02T18:23:00+0000   \n",
              "96  2018-11-30T11:38:30+0000   \n",
              "97  2016-07-22T11:44:12+0000   \n",
              "98  2011-11-17T11:50:06+0000   \n",
              "99  2021-02-19T16:48:01+0000   \n",
              "\n",
              "                                    short_description  \\\n",
              "0   This is the daily notebook of Mike Santoli, CN...   \n",
              "1   This commentary originally ran on Facebook. Bo...   \n",
              "2   In spring, ambitious reforms began in Italy. U...   \n",
              "3   The US government is increasingly likely to co...   \n",
              "4                                                 NaN   \n",
              "..                                                ...   \n",
              "95  (Adds comment, details, updates prices)* Spain...   \n",
              "96  Cryptocurrencies are nearing the end of the ro...   \n",
              "97  It's been 351 days since Jon Stewart sat behin...   \n",
              "98  Stock markets have taken such a beating over t...   \n",
              "99  President Joe Biden said Friday that he plans ...   \n",
              "\n",
              "                                             keywords  \\\n",
              "0   cnbc, Premium, Articles, Investment strategy, ...   \n",
              "1   Articles, Politics, Europe News, European Cent...   \n",
              "2   Articles, Business News, Economy, Europe Econo...   \n",
              "3   cnbc, Articles, General Motors Co, Business Ne...   \n",
              "4   cnbc, Articles, George W. Bush, Vladimir Putin...   \n",
              "..                                                ...   \n",
              "95  cnbc, Articles, Caterpillar Inc, Europe, Washi...   \n",
              "96  cnbc, Articles, Bitcoin/USD Bitfinex, Economy,...   \n",
              "97  cnbc, Articles, Donald Trump, Media, Elections...   \n",
              "98  cnbc, Articles, Business News, Economy, World ...   \n",
              "99  cnbc, Articles, Breaking News: Politics, Joe B...   \n",
              "\n",
              "                                          description  \n",
              "0   This is the daily notebook of Mike Santoli, CN...  \n",
              "1                                                 NaN  \n",
              "2                                                 NaN  \n",
              "3   The US government is increasingly likely to co...  \n",
              "4   President Donald Trump hailed the U.S.-led int...  \n",
              "..                                                ...  \n",
              "95  (Adds comment, details, updates prices)* Spain...  \n",
              "96  Cryptocurrencies are nearing the end of the ro...  \n",
              "97  It's been 351 days since Jon Stewart sat behin...  \n",
              "98  Stock markets have taken such a beating over t...  \n",
              "99  President Joe Biden said Friday that he plans ...  \n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fpath = \"cnbc_news_datase.csv\" # \"/content/drive/My Drive/cnbc_news_datase.csv\"\n",
        "\n",
        "#-------Read in article data-------\n",
        "# FILE MUST BE UPLOADED TO YOUR DRIVE; NOTE: if using Collab, also remember to use the second \"/content\" filepath\n",
        "news = pd.read_csv(fpath, usecols = [1, 3, 6,  7, 10])\n",
        "#-------Check data-------\n",
        "news.head(100) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "KbI9Msb742U_"
      },
      "outputs": [],
      "source": [
        "#--------------Define some helper functions for next code block--------------\n",
        "\n",
        "# NOTE: datetime.datetime.fromisoformat or datetime.date.fromisoformat is better\n",
        "def to_time(date_string: str) -> datetime.datetime:\n",
        "  '''Turns a str in desired format to datetime.datetime'''\n",
        "  return datetime.datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S%z\").replace(tzinfo=None)\n",
        "\n",
        "# NOTE: unused class. Consider removing.\n",
        "class NewsArticle: # Class to represent and manipulate NewsArticle objects\n",
        "  def __init__(self, id: int, title: str, date: str, keywords: list[str], description: str, short_description: str):\n",
        "    '''Creates a stock object with the given fields'''\n",
        "    self.id = id\n",
        "    self.title = title\n",
        "    self.keywords = keywords.split(\", \")\n",
        "    self.date = to_time(date)\n",
        "    self.description = description\n",
        "    self.short_description = short_description\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "    '''Gives a string representation of the object using its id, title, short_description, and date fields'''\n",
        "    return f'{str(self.id)}: {str(self.title)}: {str(self.short_description)}: ({str(self.date)})'\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    '''Gives a string representation of the object using its id, title, short_description, date, and keywords fields'''\n",
        "    return f'{str(self.title)}: {str(self.description)}: ({str(self.date)}); keywords: {str(self.keywords)}'\n",
        "\n",
        "  def add_keyword(self, keyword) -> None:\n",
        "    '''Adds a keyword to the list of the article's keywords'''\n",
        "    self.keywords.append(keyword)\n",
        "\n",
        "  def contains_keyword(self, keyword_to_find) -> bool:\n",
        "    '''Checks if article contains given keyword'''\n",
        "    for keyword in self.keywords:\n",
        "      if keyword_to_find in keyword:\n",
        "        return True\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load news articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-4FqkBi7mAe",
        "outputId": "60a22c51-b2b9-42b2-99cd-cc50c6f95f32"
      },
      "outputs": [],
      "source": [
        "#-------Globals-------\n",
        "# rename to avoid changing all occurrences just for a different alias\n",
        "articles = news\n",
        "\n",
        "#-------Clean articles a bit-------\n",
        "# fix date\n",
        "articles['date'] = articles[\"published_at\"].apply(lambda x: to_time(x))\n",
        "articles = articles.drop(\"published_at\", axis=1)\n",
        "# fix caps\n",
        "str_cols = [\"description\", \"short_description\", \"title\"]\n",
        "articles[str_cols] = articles[str_cols].apply(lambda x: x.str.lower() if x.dtype == 'O' else x)\n",
        "# fix caps in keywords and turn -> np.array\n",
        "articles['keywords'] = articles['keywords'].map(lambda keyword_list: np.array([keyword.lower() for keyword in keyword_list.split(\",\")]))\n",
        "\n",
        "##-------OUTDATED CODE-------\n",
        "# articles = []\n",
        "# for j in range(len(news)): # process news article objects\n",
        "#   article = NewsArticle(j, news.iloc[j][0], news.iloc[j][1], news.iloc[j][3], news.iloc[j][4], news.iloc[j][2])\n",
        "#   articles.append(article)\n",
        "##-------TEST CODE-------\n",
        "# articles = articles.drop(0, axis=1)\n",
        "# print(articles['date'].min())\n",
        "# print(articles['date'].max())\n",
        "\n",
        "# print(articles.head())\n",
        "\n",
        "# NOTE: this function is here, but has not been use\n",
        "# Consider removing it.\n",
        "def find_relevant_articles(article_df: pd.DataFrame, keyword: str, range_start: int = 0, range_end: int = 500) -> pd.DataFrame:\n",
        "    '''function to find relevant articles for a given keyword'''\n",
        "    if range_start < 0:\n",
        "        return \"Invalid start index\"\n",
        "\n",
        "    # convert keyword to normal format\n",
        "    # doing this later is costly\n",
        "    keyword = keyword.lower()\n",
        "\n",
        "    # inner -> outer\n",
        "    # 1. make a vector of true/false if the keyword is found anywhere in that row's keywords\n",
        "    # 2. get every row where that vector holds true\n",
        "    # 3. get every row limited by the given range\n",
        "    return article_df.loc[\n",
        "            range_start:min(range_end, len(article_df)) - 1\n",
        "            ].loc[\n",
        "                article_df['keywords'].apply(lambda keyword_list: any(keyword in current_keyword.casefold() for current_keyword in keyword_list))\n",
        "              ]\n",
        "\n",
        "# #-------TEST CODE-------\n",
        "# print(\"Articles about Donald Trump:\")\n",
        "# ex_list = find_relevant_articles(articles, \"Donald Trump\", 0, 200)\n",
        "# print(ex_list.head())\n",
        "# print(f'Example keyword representation {ex_list.iloc[0][\"keywords\"]}')\n",
        "# print(\"\\nArticles about Bitcoin:\")\n",
        "# ex_list = find_relevant_articles(articles, \"cnbc\", 0, 300)\n",
        "# print(ex_list.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5yY1z5X_HTF",
        "outputId": "97636e05-2d1b-4b40-f2dc-e9c50dccfd30"
      },
      "outputs": [],
      "source": [
        "# # Entity recognition demo\n",
        "# import spacy\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # print entities of first ten articles\n",
        "# # for i in range(10):\n",
        "# #   doc = nlp(articles[i].description) # process article text\n",
        "# #   print(articles[i])\n",
        "# #   for ent in doc.ents:\n",
        "# #       # Print the entity text and its label\n",
        "# #       print(ent.text, ent.label_)\n",
        "\n",
        "# doc = nlp('''Alphabet is a holding company. Internet media giant Google is a wholly owned subsidiary. Google generates 99% of Alphabet revenue, of which more than 85% is from online ads. Google's other revenue is from sales of apps and content on Google Play and YouTube, as well as cloud service fees and other licensing revenue. Sales of hardware such as Chromebooks, the Pixel smartphone, and smart home products, which include Nest and Google Home, also contribute to other revenue. Alphabet's moonshot investments are in its other bets segment, where it bets on technology to enhance health (Verily), faster internet access to homes (Google Fiber), self-driving cars (Waymo), and more. Alphabet's operating margin has been 25%-30%, with Google at 30% and other bets operating at a loss.\n",
        "# ''')\n",
        "# for ent in doc.ents:\n",
        "#   print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter Articles outside of the Date Range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "W8bkvTElPD7T",
        "outputId": "a60f4370-b4ec-4690-a70a-4de450c06da2"
      },
      "outputs": [],
      "source": [
        "#-------Constants-------\n",
        "# How many days to keep track of after any given article\n",
        "DAYS_AFTER = 10\n",
        "\n",
        "#-------Download stock market data -> ****hold****-------\n",
        "%run load_stocks.ipynb\n",
        "hold = from_json(\"stocks.json\")\n",
        "# NOTE: Post condition: type(hold) = df.DataFrame(ticker: str, prices: list[float], dates: list[datetime.datetime], industry: str)\n",
        "\n",
        "#--------Process hold/articles on new information-------\n",
        "\n",
        "# find min and max stock data range and filter out articles not in that range\n",
        "all_dates = np.concatenate(hold[\"dates\"])\n",
        "min_stock_date = np.min(all_dates)\n",
        "max_stock_date = np.max(all_dates)\n",
        "del all_dates\n",
        "articles = articles[(articles['date'] >= min_stock_date) & (articles['date'] <= max_stock_date - datetime.timedelta(days=DAYS_AFTER))].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# dates_and_prices = zip(hold['ticker'].values, hold['dates'].values, hold['prices'].values)\n",
        "\n",
        "def get_date_stocks(date: datetime.datetime) -> pd.DataFrame:\n",
        "    date_range_end = (date + datetime.timedelta(days=DAYS_AFTER)).replace(tzinfo=None)\n",
        "\n",
        "    stocks = {}\n",
        "    for entry_ticker, entry_dates, entry_prices in dates_and_prices:\n",
        "        mask = entry_dates <= date_range_end\n",
        "        prices = entry_prices[mask]\n",
        "        # Calculate daily price changes\n",
        "        price_changes = np.diff(prices)\n",
        "        # Calculate average change using numpy.mean\n",
        "        stocks[entry_ticker] = np.mean(price_changes)\n",
        "\n",
        "    return pd.DataFrame(list(stocks.items()), columns=['ticker', 'price_change'])\n",
        "\n",
        "# # TEST CODE\n",
        "# print(articles)\n",
        "# hold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1WPAg-jO_xB"
      },
      "source": [
        "## Do Sentiment Analysis:\n",
        "(From ChatGPT)\n",
        "\n",
        "1. Feature Extraction\n",
        "2. Machine Learning Model Selection:\n",
        "3. Model Training\n",
        "4. Model Evaluation\n",
        "5. Inference:\n",
        "6. Fine-tuning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                date_        10  100  10004  1007  101  1015  102  103  1035  \\\n",
            "0 2016-06-24 13:50:48  0.015653  0.0    0.0   0.0  0.0   0.0  0.0  0.0   0.0   \n",
            "\n",
            "   ...  zoning  zoom  zoranradosavljevic  zscaler  zsolt  zuckerberg  \\\n",
            "0  ...     0.0   0.0                 0.0      0.0    0.0         0.0   \n",
            "\n",
            "   zuckerman  zurich  zyne  zynga  \n",
            "0        0.0     0.0   0.0    0.0  \n",
            "\n",
            "[1 rows x 18447 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import re\n",
        "#-------Vectorize articles, then run a TF-IDF library over it-------\n",
        "# Make tokenizers\n",
        "vectorizer = CountVectorizer(preprocessor=lambda word: re.sub(r'\\b0+', '', word))\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "# Put everything into col[text] to get all data in one place. get rid of other data as needed\n",
        "text_row_func = lambda row: re.sub(r'&#[0-9]+;', '', \n",
        "    f'{row[\"title\"]} {row[\"short_description\"]} {row[\"description\"] if pd.notna(row[\"description\"]) else \"\"} {\" \".join(row[\"keywords\"])}'\n",
        "    )\n",
        "# Tokenize\n",
        "tfidf_matrix = tfidf_transformer.fit_transform(vectorizer.fit_transform(articles.apply(text_row_func, axis=1)))\n",
        "# Extract column names (i.e., the words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "# Update the articles dataset with the TF-IDF vector on each article\n",
        "# NOTE: all other information thrown away; only the date and the TF-IDF vector kept\n",
        "#   - the date will be thrown away later as well, and there will be a parallel vector of the prices\n",
        "articles = articles.rename(columns={\"date\": \"date_\"})\n",
        "articles = pd.concat([articles[\"date_\"], pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)], axis=1)\n",
        "# test a single row (1 x ~20000) vs (~600 x ~20000)\n",
        "print(articles.head(1))\n",
        "len(articles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'float' and 'datetime.timedelta'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X \u001b[39m=\u001b[39m articles[[\u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]]  \u001b[39m# Assuming 'date' is a datetime column\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Replace 'actual_target_column' with the actual column name you want to predict\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y \u001b[39m=\u001b[39m articles[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: get_date_stocks(row))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X \u001b[39m=\u001b[39m articles[[\u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]]  \u001b[39m# Assuming 'date' is a datetime column\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Replace 'actual_target_column' with the actual column name you want to predict\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y \u001b[39m=\u001b[39m articles[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: get_date_stocks(row))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
            "\u001b[1;32m/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_date_stocks\u001b[39m(date: datetime\u001b[39m.\u001b[39mdatetime) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     date_range_end \u001b[39m=\u001b[39m (date \u001b[39m+\u001b[39;49m datetime\u001b[39m.\u001b[39;49mtimedelta(days\u001b[39m=\u001b[39;49mDAYS_AFTER))\u001b[39m.\u001b[39mreplace(tzinfo\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     stocks \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X51sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mfor\u001b[39;00m entry_ticker, entry_dates, entry_prices \u001b[39min\u001b[39;00m dates_and_prices:\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'datetime.timedelta'"
          ]
        }
      ],
      "source": [
        "# Data Split. Import y'value array from other\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your input (X) and output (y) variables\n",
        "X = articles[['keywords', 'title']]  # Assuming 'date' is a datetime column\n",
        "# Replace 'actual_target_column' with the actual column name you want to predict\n",
        "y = articles['date'].apply(lambda row: get_date_stocks(row))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g-B-3RXiPLYX",
        "outputId": "1895e280-9829-4ebe-9c84-236985133086"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'price_change'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'price_change'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Machine Learning Model: Linear Regression\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m linear_reg \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m linear_reg\u001b[39m.\u001b[39mfit(x_train, y_train[\u001b[39m'\u001b[39;49m\u001b[39mprice_change\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mflatten())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saad/Documents/School/CS/SIGNLL_Workshops/NewsSentimentAnalysis/StockMarketPrediction/News_Data_Processing.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m predictions \u001b[39m=\u001b[39m linear_reg\u001b[39m.\u001b[39mpredict(x_test)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'price_change'"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Machine Learning Model: Linear Regression\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(x_train, y_train['price_change'].values.flatten())\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = linear_reg.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
